{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "y = np.sin(2 * math.pi * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5\n",
    "np.random.seed(123456)\n",
    "sample_x = np.random.choice(x, size=sample_size, replace=False)\n",
    "sample_y = np.sin(2 * math.pi * sample_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla setting (explicit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_gaussian(x1, x2):\n",
    "    # calculating gaussian kernel matrix\n",
    "    # the output has shape (len(x2), len(x1))\n",
    "    # entry at [i, j] position is given by k(x2[i], x1[j])\n",
    "    \n",
    "    # gaussian kernel hyperparameters - adjusts the distance between points and variance\n",
    "    l = 0.1\n",
    "    sigma = 1\n",
    "    \n",
    "    x1_matrix = np.tile(x1, len(x2)).reshape((len(x2), len(x1)))\n",
    "    x2_matrix = np.tile(x2, len(x1)).reshape((len(x1), len(x2))).transpose()\n",
    "    \n",
    "    k_matrix = np.exp(-(x1_matrix - x2_matrix) ** 2 / (2 * l * l)) * sigma ** 2\n",
    "    \n",
    "    return k_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gp_posterior(sample_x, sample_y, x):\n",
    "    # calculating posterior for gaussian processes\n",
    "    # it is assumed that observations have some additional gaussian noise\n",
    "    \n",
    "    sigma_obs = 0.1  \n",
    "    \n",
    "    # Separately calculating matrix used to calculate both mean and variance\n",
    "    K = np.dot(k_gaussian(sample_x, x),\n",
    "               np.linalg.inv(k_gaussian(sample_x, sample_x) + np.eye(len(sample_x)) * sigma_obs ** 2)\n",
    "              )\n",
    "    \n",
    "    mu = np.dot(K, sample_y)\n",
    "    sigma = k_gaussian(x, x) - np.dot(K, k_gaussian(x, sample_x))\n",
    "    \n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = gp_posterior(sample_x, sample_y, x)\n",
    "std_1d = np.sqrt([sigma[i, i] for i in range(len(mu))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, label=\"signal\")\n",
    "plt.plot(sample_x, sample_y, \".\", color=\"r\", label=\"obs\")\n",
    "plt.plot(x, mu, color=\"g\", label=\"posterior\")\n",
    "plt.fill_between(x, mu - 2 * std_1d, mu + 2 * std_1d, color=\"g\", alpha=0.5)\n",
    "\n",
    "plt.title(\"True and recovered signals\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla setting (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main difference so far: sklearn implementation actually estimates kernel hyperparameters through ML (becase of beta0=None), n_restarts specifies how many times ML is performed when starting from random points, noise in observed data is handled via alpha (is specifies the value to add along the main diagonal when inverting kernel matrix for observations)\n",
    "\n",
    "(hopefully, it will be more stable when it comes to cholesky decomposition in later applications) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=RBF(length_scale=0.1),\n",
    "                              alpha=0.01,\n",
    "                              n_restarts_optimizer=100,\n",
    "                              normalize_y=False\n",
    "                             )\n",
    "\n",
    "gp.fit(sample_x.reshape(-1, 1), sample_y.reshape(-1, 1))\n",
    "\n",
    "mu, std_1d = gp.predict(x.reshape(-1, 1), return_std=True)\n",
    "std_1d = std_1d.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, label=\"signal\")\n",
    "plt.plot(sample_x, sample_y, \".\", color=\"r\", label=\"obs\")\n",
    "plt.plot(x, mu, color=\"g\", label=\"posterior\")\n",
    "plt.fill_between(x, (mu - 2 * std_1d).reshape(-1), (mu + 2 * std_1d).reshape(-1), color=\"g\", alpha=0.5)\n",
    "\n",
    "plt.title(\"True and recovered signals\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
